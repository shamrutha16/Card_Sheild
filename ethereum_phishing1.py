# -*- coding: utf-8 -*-
"""Ethereum_phishing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZSzE_XDrDbiyhY1XP779jVMsuS6d8scn
"""

from google.colab import drive
drive.mount('/content/drive')

# üõ†Ô∏è Step 1: Install Required Libraries
!pip install networkx==3.2 matplotlib torch torchvision torchaudio torch-geometric xgboost scikit-learn --quiet

# üóÇÔ∏è Step 2: Import Required Libraries
import pandas as pd
import networkx as nx
import torch
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
from zipfile import ZipFile
from google.colab import files

# üì• Step 3: Upload and Extract Dataset
uploaded = files.upload()  # Upload ethereum_phishing_dataset.zip manually

with ZipFile("ethereum_phishing_dataset.zip", 'r') as zip_ref:
    zip_ref.extractall("ethereum_phishing_dataset")

# üìÑ Step 4: Load Dataset
accounts_df = pd.read_csv("ethereum_phishing_dataset/accounts.csv")
transactions_df = pd.read_csv("ethereum_phishing_dataset/transactions.csv")

# üß† Step 5: Encode Account IDs
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
accounts_df["index"] = le.fit_transform(accounts_df["account_id"])
account_index_map = dict(zip(accounts_df["account_id"], accounts_df["index"]))

# üßæ Step 6: Create NetworkX Graph
G = nx.DiGraph()
for _, row in accounts_df.iterrows():
    G.add_node(row["index"], phishing=row["is_phishing"], account=row["account_id"])

for _, row in transactions_df.iterrows():
    src = account_index_map[row["from_account"]]
    dst = account_index_map[row["to_account"]]
    G.add_edge(src, dst, amount=row["amount"], timestamp=row["timestamp"])

# üé® Step 7: Visualize the Graph
plt.figure(figsize=(10, 8))
node_colors = ['red' if G.nodes[n]['phishing'] == 1 else 'blue' for n in G.nodes()]
pos = nx.spring_layout(G, seed=42)
nx.draw(G, pos, with_labels=True, node_color=node_colors, arrows=True, edge_color='gray', node_size=800)
plt.title("Ethereum Transaction Graph (Red = Phishing, Blue = Normal)")
plt.show()

# üß™ Step 8: Prepare Graph Data for PyTorch Geometric
edges = list(G.edges())
edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
x = torch.eye(len(G.nodes))  # One-hot encoding
labels = [G.nodes[i]['phishing'] for i in range(len(G.nodes))]
y = torch.tensor(labels, dtype=torch.long)
data = Data(x=x, edge_index=edge_index, y=y)

# üß† Step 9: Define GCN Encoder Model
class GCNEncoder(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index)
        return x

# üöÄ Step 10: Train GCN and Extract Features
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = GCNEncoder(in_channels=data.num_node_features, hidden_channels=64).to(device)
data = data.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
model.train()
for epoch in range(101):
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = torch.nn.functional.cross_entropy(out, data.y)
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        print(f"Epoch {epoch} - Loss: {loss.item():.4f}")

# üß† Step 11: Classify with XGBoost
model.eval()
with torch.no_grad():
    embeddings = model(data.x, data.edge_index).cpu().numpy()
labels = data.y.cpu().numpy()

X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.3, random_state=42)
clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("\nüìä Classification Report:")
print(classification_report(y_test, y_pred, target_names=["Normal", "Phishing"]))

!pip install streamlit pyngrok pandas networkx torch torch-geometric xgboost scikit-learn plotly

# Commented out IPython magic to ensure Python compatibility.
# # Step 4.1: Write the Streamlit app to a file
%%writefile app.py
import streamlit as st
import pandas as pd
import networkx as nx
import torch
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
import json
import time
import base64
# 
# # Streamlit page config
st.set_page_config(page_title="Ethereum Phishing Detector", layout="wide")
# 
# # Simple user authentication using session state
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
# 
if not st.session_state.authenticated:
    st.title("Login to Access the App")
    password = st.text_input("Enter Password", type="password")
    if st.button("Login"):
        if password == "phishing_detector":  # Replace with a secure password
            st.session_state.authenticated = True
            st.rerun()

        else:
            st.error("Incorrect password")
    st.stop()

# # If authenticated, show the app
st.title("Ethereum Phishing Detection Using GNN")
st.markdown("""
# Upload your accounts.csv, transactions.csv, and graph.json to detect phishing accounts using Graph Neural Networks (GCN) and XGBoost.
# Customize model parameters in the sidebar.
# """)
# 
# # Sidebar for customizable parameters
st.sidebar.header("Model Parameters")
hidden_channels = st.sidebar.slider("GCN Hidden Channels", min_value=8, max_value=64, value=16, step=8)
training_epochs = st.sidebar.slider("Training Epochs", min_value=50, max_value=200, value=100, step=10)
# 
# # File uploaders (use Colab paths)
accounts_file = st.file_uploader("Upload accounts.csv", type="csv")
transactions_file = st.file_uploader("Upload transactions.csv", type="csv")
graph_file = st.file_uploader("Upload graph.json", type="json")

if accounts_file and transactions_file and graph_file:
    try:
#         # Load data
        accounts_df = pd.read_csv(accounts_file)
        transactions_df = pd.read_csv(transactions_file)
        graph_data = json.load(graph_file)
# 
#         # Encode account IDs
        le = LabelEncoder()
        accounts_df["index"] = le.fit_transform(accounts_df["account_id"])
        account_index_map = dict(zip(accounts_df["account_id"], accounts_df["index"]))

#         # Create NetworkX graph from graph.json (fallback to CSVs if needed)
        G = nx.DiGraph()
        for node in graph_data.get("nodes", []):
            G.add_node(node["id"], label=node["label"])
        for edge in graph_data.get("edges", []):
            G.add_edge(edge["source"], edge["target"], amount=edge.get("amount"), timestamp=edge.get("timestamp"))

#         # If graph.json is incomplete, supplement with CSVs
        for _, row in accounts_df.iterrows():
            if row["account_id"] not in G:
                G.add_node(row["account_id"], label="phishing" if row["is_phishing"] else "normal")
        for _, row in transactions_df.iterrows():
            if not G.has_edge(row["from_account"], row["to_account"]):
                G.add_edge(row["from_account"], row["to_account"], amount=row["amount"], timestamp=row["timestamp"])
# 
#         # Visualize graph with Plotly
        st.subheader("Transaction Graph Visualization")
        pos = nx.spring_layout(G)
        edge_x, edge_y = [], []
        for edge in G.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])

        edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=0.5, color='#888'), hoverinfo='none', mode='lines')

        node_x, node_y, node_text, node_color = [], [], [], []
        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            node_text.append(f"Account: {node}\nLabel: {G.nodes[node].get('label', 'unknown')}")
            node_color.append('red' if G.nodes[node].get('label') == 'phishing' else 'green')# 
        node_trace = go.Scatter(x=node_x, y=node_y, mode='markers', hoverinfo='text', text=node_text,
                                marker=dict(showscale=False, color=node_color, size=10, line_width=2))# 
        fig = go.Figure(data=[edge_trace, node_trace], layout=go.Layout(
            title='Ethereum Transaction Graph', titlefont_size=16, showlegend=False,
            hovermode='closest', margin=dict(b=20, l=5, r=5, t=40),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))
        st.plotly_chart(fig, use_container_width=True)
 
#         # GNN Model Definition (customizable hidden channels)
        class GCN(torch.nn.Module):
            def __init__(self, in_channels, hidden_channels, out_channels):
                super(GCN, self).__init__()
                self.conv1 = GCNConv(in_channels, hidden_channels)
                self.conv2 = GCNConv(hidden_channels, out_channels)
 
            def forward(self, x, edge_index):
                x = self.conv1(x, edge_index).relu()
                x = self.conv2(x, edge_index)
                return x
# 
#         # Prepare PyG data
        num_nodes = len(G.nodes)
        node_list = list(G.nodes)
        node_index = {node: i for i, node in enumerate(node_list)}
        x = torch.eye(num_nodes)  # Identity matrix as node features
        edge_index_list = [(node_index[src], node_index[dst]) for src, dst in G.edges]
        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()
        y = torch.tensor([1 if G.nodes[node].get('label') == 'phishing' else 0 for node in node_list], dtype=torch.long)
        data = Data(x=x, edge_index=edge_index, y=y)
 
#         # Train GNN and classify with XGBoost
        if st.button("Run Phishing Detection"):
            model = GCN(in_channels=num_nodes, hidden_channels=hidden_channels, out_channels=8)
            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
            criterion = torch.nn.CrossEntropyLoss()
 
#             # Progress bar for training
            progress_bar = st.progress(0)
            status_text = st.empty()
            model.train()
            for epoch in range(training_epochs):
                optimizer.zero_grad()
                out = model(data.x, data.edge_index)
                loss = criterion(out, data.y)
                loss.backward()
                optimizer.step()
 
#                 # Update progress
                progress = (epoch + 1) / training_epochs
                progress_bar.progress(progress)
                status_text.text(f"Training Epoch: {epoch + 1}/{training_epochs} | Loss: {loss.item():.4f}")
                time.sleep(0.01)  # Simulate training time; remove in production
# 
            status_text.text("Training complete!")
# 
            model.eval()
            with torch.no_grad():
                embeddings = model(data.x, data.edge_index).cpu().numpy()
            labels = data.y.cpu().numpy()
 
            X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.3, random_state=42)
            clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
            clf.fit(X_train, y_train)
            y_pred = clf.predict(X_test)
 
            st.subheader("Classification Report")
            report = classification_report(y_test, y_pred, target_names=["Normal", "Phishing"], output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)
 
#             # Detected phishing accounts
            node_df = pd.DataFrame({
                "account_id": node_list,
                "true_label": labels,
                "predicted_label": clf.predict(embeddings)  # Predict on all for full results
            })
            phishing_accounts = node_df[node_df['predicted_label'] == 1]['account_id'].tolist()
            st.subheader("Detected Phishing Accounts")
            st.write(phishing_accounts)
 
#             # Download prediction results as CSV
            csv = node_df.to_csv(index=False)
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="predictions.csv">Download Predictions as CSV</a>'
            st.markdown(href, unsafe_allow_html=True)
 
    except Exception as e:
        st.error(f"Error processing files: {str(e)}")
 
# Footer
st.markdown("---\nBuilt with Streamlit | Enhanced for Customization and Security")


# Step 4.2: Run Streamlit with ngrok (in the same cell or a new one)
from pyngrok import ngrok
import os

# Set up ngrok authtoken (get your free token from ngrok.com/dashboard)
ngrok.set_auth_token("315S39qix0pSIUdAl6RcxUHHg2j_5JMhfEWmhGBLMLf98L8ff")  # Replace with your actual token

# Kill any existing tunnels
ngrok.kill()

# Start Streamlit in background
os.system("streamlit run app.py &")

# Create public URL
public_url = ngrok.connect(8501)
print(f"Streamlit app is live at: {public_url}")